# -*- coding: utf-8 -*-
"""Bank Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mhguvuVrP-98NFq0ufr1rGA6q1KTbPWj

# BANK CHURN PREDICTION
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Import Required Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import ConfusionMatrixDisplay,f1_score
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
from sklearn.metrics import roc_curve,f1_score, auc



import warnings
warnings.filterwarnings('ignore')

"""# Loading Data Set"""

df = pd.read_csv('/content/drive/MyDrive/Bank Churn Prediction/Bank_Churn.csv')
df

df.head()

"""# Checking Null Values"""

df.isnull().sum()

"""# Checking Data type"""

df.info()

"""# Counting 1 and 0 Value in Exited column"""

df['Exited'].value_counts()

# Removing customer_id ,Surname
df= df.drop(['CustomerId','Surname'],axis=1)
df.head()

df['Geography'].unique()

df['Geography'].value_counts()

# converting object datatype to numerical datatype(int64)
df['Geography']=df['Geography'].replace(['France'],'0')
df['Geography']=df['Geography'].replace(['Germany'],'1')
df['Geography']=df['Geography'].replace(['Spain'],'2')

df['Gender'].unique()

df['Gender'].value_counts()

df['Age'].value_counts()

# changing object datatype to numerical datatype(int64)
df['Gender']=df['Gender'].replace(['Male'],'0')
df['Gender']=df['Gender'].replace(['Female'],'1')

df.head(5)

"""# Conver object data type column to int64"""

df.info()

df['Geography']=pd.to_numeric(df['Geography'])
df['Gender']=pd.to_numeric(df['Gender'])

df.info()

"""# EDA"""

corrmat = df.corr()
sns.heatmap(corrmat,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size':10})
plt.show()

"""
# Build Machine Learning Model"""

X = df.drop(columns=['Exited'])
Y = df[['Exited']]

"""# Split Data into Train And Test data sets"""

x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state=42)

print(x_train.shape)
print(y_train.shape)

print(x_test.shape)
print(y_test.shape)

x_train.head(5)

y_train.head(5)

x_train.isnull()

x_train.isnull().sum()

"""# Outlier Treatment"""

x_train.boxplot(['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary'])

x_train.boxplot(['Balance','EstimatedSalary'])

"""# this dataset doesn't has outliers

# Statistical Summary of your data
"""

x_train.describe()

"""# LogisticRegression

"""

lr=LogisticRegression(class_weight={0:1,1:2},max_iter=500,random_state=42)
lr.fit(x_train,y_train)

"""# prediction and confusion matrix"""

tr_pred0=lr.predict(x_train)
val_pred0=lr.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_train,tr_pred0)
ConfusionMatrixDisplay.from_predictions(y_test,val_pred0)

"""# F1_SCORE"""

train_f1=f1_score(y_train,tr_pred0)
val_f1=f1_score(y_test,val_pred0)
print('Train f1 score -{}'.format(train_f1))
print('val f1 score -{}'.format(val_f1))

"""# Accuracy Score"""

print('Accuracy Score: ',accuracy_score(y_test,val_pred0))

"""# Classification report"""

print('Classification report - ',classification_report(y_test,val_pred0))

"""# LogisticRegression"""

lr1=LogisticRegression()
lr1.fit(x_train,y_train)

"""# prediction and confusion matrix"""

tr_pred_lr=lr1.predict(x_train)
val_pred_lr=lr1.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_train,tr_pred_lr)
ConfusionMatrixDisplay.from_predictions(y_test,val_pred_lr)

"""# F1_SCORE"""

train_f1=f1_score(y_train,tr_pred_lr)
val_f1=f1_score(y_test,val_pred_lr)
print('Train f1 score -{}'.format(train_f1))
print('val f1 score -{}'.format(val_f1))

"""# Accuracy Score"""

print('Accuracy Score: ',accuracy_score(y_test,val_pred_lr))

"""# Classification report"""

print('Classification report - ',classification_report(y_test,val_pred_lr))

"""# Decision Tree with cart(gini)"""

Dt=DecisionTreeClassifier(random_state=1,max_depth=2)
Dt.fit(x_train,y_train)
train_score=Dt.score(x_train,y_train)
test_score=Dt.score(x_test,y_test)
print('Training Score: ',train_score)
print('Testing Score: ',test_score)

"""# Decision Tree with entropy"""

Dt1=DecisionTreeClassifier(random_state=1,max_depth=8,criterion='entropy')
Dt1.fit(x_train,y_train)
train_score=Dt.score(x_train,y_train)
test_score=Dt.score(x_test,y_test)
print('Training Score: ',train_score)
print('Testing Score: ',test_score)

"""# model prediction"""

tr_pred=Dt1.predict(x_train)
val_pred=Dt1.predict(x_test)

"""# confusion Matrix Display"""

ConfusionMatrixDisplay.from_predictions(y_train,tr_pred)
ConfusionMatrixDisplay.from_predictions(y_test,val_pred)

"""# F1_score"""

train_f1=f1_score(y_train,tr_pred)
val_f1=f1_score(y_test,val_pred)
print('Train f1 score -{}'.format(train_f1))
print('val f1 score -{}'.format(val_f1))

"""# Accuracy score"""

print('Accuracy Score: ',accuracy_score(y_test,val_pred))

"""# Classification Report"""

print('Classification report :',classification_report(y_test,val_pred))

"""# Random Forest"""

rf=RandomForestClassifier()
rf.fit(x_train,y_train)

tr1_pred=rf.predict(x_train)
val1_pred=rf.predict(x_test)

"""# ConfusionMatrixDisplay,f1_score"""

ConfusionMatrixDisplay.from_predictions(y_train,tr1_pred)
ConfusionMatrixDisplay.from_predictions(y_test,val1_pred)

train_f1 = f1_score(y_train,tr1_pred)
val_f1 = f1_score(y_test,val1_pred)

print("train F1 Score - {}".format(train_f1))
print("val F1 Score - {}".format(val_f1))

"""# Accuracy Score"""

print('Accuracy Score: ',accuracy_score(y_test,val1_pred))

"""# Classification report"""

print('Classification report :',classification_report(y_test,val1_pred))

fpr_rf,tpr_rf,_=roc_curve(y_test,val1_pred)
roc_auc_rf=auc(fpr_rf,tpr_rf)

plt.figure(15)
lw=2
plt.plot(fpr_rf,tpr_rf,color='orange',lw=lw,label='rf(AUC = %0.2f)'%roc_auc_rf)
plt.plot([0,1],[0,1],color='blue',lw=lw,linestyle='--')

plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('area under the curve')
plt.legend(loc='lower right')

"""# Extract feature importances"""

# Extract feature importances
feature_importances = rf.feature_importances_

# Calculate percentages
importance_percentages = (feature_importances / np.sum(feature_importances)) * 100

# Feature names or indices
feature_names = [f'Feature {i}' for i in range(X.shape[1])]

# Sort features by importance
sorted_indices = np.argsort(importance_percentages)[::-1]
sorted_features = [feature_names[i] for i in sorted_indices]
sorted_importances = importance_percentages[sorted_indices]

# Plot feature importances with percentages and feature names
plt.figure(figsize=(10, 6))
plt.barh(sorted_features, sorted_importances, color='skyblue')
plt.xlabel('Importance (%)')
plt.ylabel('Features')
plt.title('Feature Importance (as Percentages)')
plt.gca().invert_yaxis()  # Invert y-axis for a top-down plot
plt.show()

# For rf is a trained RandomForest model
importances = rf.feature_importances_
feature_names = rf.feature_names_in_

# Create a DataFrame and sort by importance
sorted_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10,12))
sns.barplot(x='Importance', y='Feature', data=sorted_importances)
plt.xticks(rotation=90)
plt.title("Feature Importance")
plt.show()

"""# Support Vector Machine"""

svm=SVC(class_weight={0:1,1:2},C=0.99,degree=6,random_state=42)
svm.fit(x_train,y_train)

tr_pred1 = svm.predict(x_train)
val_pred1 = svm.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_train,tr_pred1)
ConfusionMatrixDisplay.from_predictions(y_test,val_pred1)

train_f1 = f1_score(y_train,tr_pred1)
val_f1 = f1_score(y_test,val_pred1)

print("train F1 Score - {}".format(train_f1))
print("val F1 Score - {}".format(val_f1))

# Accuracy Score
print('Accuracy Score: ',accuracy_score(y_test,val_pred1))

print('Classification report :',classification_report(y_test,val_pred1))

"""# XGBOOST"""

xgb=XGBClassifier()
xgb.fit(x_train,y_train)

"""# model prediction"""

tr_pred2 = xgb.predict(x_train)
val_pred2 = xgb.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_train,tr_pred2)
ConfusionMatrixDisplay.from_predictions(y_test,val_pred2)

train_f1 = f1_score(y_train,tr_pred2)
val_f1 = f1_score(y_test,val_pred2)

print("train F1 Score - {}".format(train_f1))
print("val F1 Score - {}".format(val_f1))

"""# Accuracy score"""

print('Accuracy Score: ',accuracy_score(y_test,val_pred2))

"""# Classification report"""

print('Classification report :',classification_report(y_test,val_pred2))

"""# Area under the curve"""

fpr_xgb,tpr_xgb,_=roc_curve(y_test,val_pred2)
roc_auc_xgb=auc(fpr_xgb,tpr_xgb)

plt.figure(1)
lw=2
plt.plot(fpr_xgb,tpr_xgb,color='orange',lw=lw,label='xgb(AUC = %0.2f)'%roc_auc_xgb)
plt.plot([0,1],[0,1],color='blue',lw=lw,linestyle='--')

plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('area under the curve')
plt.legend(loc='lower right')

#  model names and their accuracy scores
models = ['LogisticRegression', 'Decision Tree','Random Forest', 'SVM', 'XGBoost']
accuracy = [0.79, 0.85, 0.866, 0.80, 0.863]

# Create bar chart
plt.figure(figsize=(8, 6))
plt.bar(models, accuracy, color=['blue', 'green', 'red', 'purple', 'orange'])

# Labels and title
plt.xlabel('Machine Learning Models', fontsize=12)
plt.ylabel('Accuracy Score', fontsize=12)
plt.title('Model Comparison - Accuracy', fontsize=14, fontweight='bold')

# Rotate x-axis labels for better visibility
plt.xticks(rotation=30)
plt.show()

"""# Conclusion
Customer churn is a major challenge for banks, as it affects both revenue and the long-term value of customers. This project aimed to build a machine learning model that can predict whether a customer is likely to leave the bank (churn), using information such as demographics, financial data, and account activity.

Our predictive model classifies customers as either likely to stay (Exited = 0) or leave (Exited = 1). The most important factors influencing churn were identified as **Age**, **Estimated Salary**, **Credit Score**, and **Account Balance**.

Among the models tested, **Random Forest** and **XGBoost** performed the best, each achieving an accuracy of **86%**.

Since the dataset was imbalanced (more non-churners than churners), we applied **resampling techniques** to the training data to improve the model's ability to detect customers likely to churn. However, further improvement can be achieved by experimenting with more advanced sampling methods.

To prepare the data for modeling, we converted categorical variables like **Geography** and **Gender** into numerical format (int64), which is required by machine learning algorithms.

We evaluated each model using a range of performance metrics, including:

* F1 Score
* Recall
* AUC (Area Under the Curve)
* Confusion Matrix
* Accuracy Score
* Classification Report

Additionally, hyperparameter tuning was applied to optimize each model for better predictions.

"""